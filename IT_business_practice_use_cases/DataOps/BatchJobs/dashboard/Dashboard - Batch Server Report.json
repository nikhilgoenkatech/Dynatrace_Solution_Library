{"version":15,"variables":[],"tiles":{"0":{"type":"code","title":"Batch Execution & Golden Signals (99th percentile) across application landscape","input":"/*\n* This function will run in the DYNATRACE JavaScript runtime.\n* For information visit https://dt-url.net/functions-help\n*/\nimport { queryExecutionClient } from '@dynatrace-sdk/client-query';\n\nexport default async function () {\n  \n  var query = `fetch bizevents\n  | filter event.type==\"batchprocessing\"\n  | summarize collectDistinct(runId), by:{\\`batchjobs-status\\`,timestamp,\\`job-name\\`}\n  | expand \\`collectDistinct(runId)\\`\n  | fieldsAdd humanreadable=formatTimestamp(timestamp, format:\"hh:mma dd/MM/yyyy\")`;\n\n  console.log(query);\n  const response = await identifyBatch(query);\n  return response;\n}\n\n//Query to fetch timeseries metrics\nasync function fetchTimeseriesMetric(metric, startTime, endTime) {\n  const timeout = 60;\n  const query = `timeseries val = percentile(` + String(metric) + `,99, rollup: avg), filter:{ in(dt.entity.service, classicEntitySelector(\"type(service),databaseName(\\\\\"TradeManagement\\\\\")\")) },from:\\\"` + String(startTime) + `\",to:\"` + String(endTime) + `\"| fieldsAdd val = arrayAvg(val)`;\n  console.log(\"Timeseries query =>\",query);\n  \n  try {\n    const response = await queryExecutionClient.queryExecute({\n      body: {\n        query,\n        requestTimeoutMilliseconds: timeout * 1000, \n        fetchTimeoutSeconds: timeout        \n      }\n    });\n    return(response.result.records[0].val);\n  } catch (error) {\n    console.error('Error executing identifyNoofJobs:', error);\n    throw error;\n  }\n}\n\n//Function to fetch host golden signals\nasync function fetchHostTimeseriesMetric(metric, startTime, endTime) {\n  const timeout = 60;\n  const query = metric + `,from:\\\"` + String(startTime) + `\",to:\"` + String(endTime) + `\\\"| fieldsAdd val = arrayAvg(val)`;\n  console.log(\"Timeseries query =>\",query);\n  \n  try {\n    const response = await queryExecutionClient.queryExecute({\n      body: {\n        query,\n        requestTimeoutMilliseconds: timeout * 1000, \n        fetchTimeoutSeconds: timeout        \n      }\n    });\n    return(response.result.records[0].val);\n  } catch (error) {\n    console.error('Error executing identifyNoofJobs:', error);\n    throw error;\n  }\n}\n\n//Function to identify the completed batch executions timeframe\nasync function identifyBatch(query) {\n  const timeout = 60;\n  try {\n    const response = await queryExecutionClient.queryExecute({ \n      body: { \n        query, \n        requestTimeoutMilliseconds: timeout * 1000, \n        fetchTimeoutSeconds: timeout \n      } \n    });\n    const recordSet = response.result.records;\n    var jobMap = {};\n  \n    for (var i = 0; i < recordSet.length; i++) {\n      var entry = recordSet[i];\n      var key = entry['job-name'] + '_' + entry['collectDistinct(runId)'];\n      \n      if (!jobMap[key]) {\n        jobMap[key] = {\n          jobName: entry['job-name'],\n          runId: entry['collectDistinct(runId)'],\n          batchStartTime:null,\n          batchEndTime:null,\n          startTime: null,\n          endTime: null\n        };\n      }\n  \n      var job = jobMap[key];\n      if (entry['batchjobs-status'] === 'STARTED') {\n        job.startTime = entry.timestamp;\n        job.batchStartTime=entry.humanreadable;\n      } else if (entry['batchjobs-status'] === 'COMPLETED') {\n        job.endTime = entry.timestamp;\n        job.batchEndTime=entry.humanreadable;\n\n      }\n    }\n  \n    var result = [];\n    for (var key in jobMap) {\n      if (jobMap.hasOwnProperty(key)) {\n        var job = jobMap[key];\n        console.log(\"JOBS\",jobMap);\n        if (job.startTime && job.endTime) {\n          console.log(\"found one\",job);\n          // Pull Service CPU\n          const cpu = await fetchTimeseriesMetric(\"dt.service.request.response_time\", job.startTime, job.endTime);\n          const count = await fetchTimeseriesMetric(\"dt.service.request.count\",job.startTime, job.endTime);\n\n          //Pull Host metrics\n          var metric = `timeseries val=percentile(dt.host.memory.usage, 99, rollup: avg), filter: { in(dt.entity.host, classicEntitySelector(\"type(host),toRelationship.isClusterOfHost(type(KUBERNETES_CLUSTER),entityName.equals(\\\\\"optimize-sre-standard\\\\\"))\")) }`;\n          const memory = await fetchHostTimeseriesMetric(metric, job.startTime, job.endTime);\n          \n          metric = `timeseries val=percentile(dt.host.cpu.usage, 99, rollup: avg), filter: { in(dt.entity.host, classicEntitySelector(\"type(host),toRelationship.isClusterOfHost(type(KUBERNETES_CLUSTER),entityName.equals(\\\\\"optimize-sre-standard\\\\\"))\")) }`;\n          const cpuhost = await fetchHostTimeseriesMetric(metric, job.startTime, job.endTime);\n          \n          job.HostMemory=memory;\n          job.HostCPU=cpuhost;\n          \n          job.DBResponse=cpu;          \n          job.DBRequests=count;\n          \n          result.push(job);\n        }\n      }\n    }\n    return result; \n  } catch (error) {\n    console.error('Error executing query:', error);\n    throw error;\n  }\n}","visualization":"table","visualizationSettings":{"thresholds":[],"chartSettings":{"gapPolicy":"connect","circleChartSettings":{"groupingThresholdType":"relative","groupingThresholdValue":0,"valueType":"relative"},"categoryOverrides":{},"curve":"linear","pointsDisplay":"auto","categoricalBarChartSettings":{"categoryAxisLabel":"jobName","valueAxisLabel":"HostMemory","tooltipVariant":"single","categoryAxis":"jobName","valueAxis":"HostMemory"},"truncationMode":"middle"},"singleValue":{"showLabel":true,"label":"","prefixIcon":"","recordField":"element","autoscale":true,"alignment":"center","colorThresholdTarget":"value"},"table":{"rowDensity":"condensed","enableSparklines":false,"hiddenColumns":[["endTime"],["startTime"]],"lineWrapIds":[],"columnWidths":{"[\"cpu\"]":205.796875,"[\"Service\"]":127.71875,"[\"startTime\"]":304.4765625},"enableThresholdInRow":false},"honeycomb":{"shape":"hexagon","legend":{"hidden":false,"position":"auto"},"colorMode":"color-palette","colorPalette":"blue","dataMappings":{"value":"HostMemory"},"displayedFields":["jobName"]},"histogram":{"dataMappings":[]},"unitsOverrides":[{"identifier":"DBResponse","unitCategory":"time","baseUnit":"microsecond","displayUnit":null,"decimals":1,"suffix":"","delimiter":false,"added":1726493334206},{"identifier":"DBRequests","unitCategory":"unspecified","baseUnit":"count_per_second","displayUnit":null,"decimals":2,"suffix":"","delimiter":false,"added":1726493399642},{"identifier":"HostMemory","unitCategory":"percentage","baseUnit":"percent","displayUnit":null,"decimals":2,"suffix":"","delimiter":false,"added":1726494918710},{"identifier":"HostCPU","unitCategory":"time","baseUnit":"microsecond","displayUnit":"millisecond","decimals":2,"suffix":"","delimiter":false,"added":1726494953269}]},"querySettings":{"maxResultRecords":1000,"defaultScanLimitGbytes":500,"maxResultMegaBytes":1,"defaultSamplingRatio":10,"enableSampling":false}},"1":{"type":"code","title":"History of batch execution & job details","input":"/*\n* This function will run in the DYNATRACE JavaScript runtime.\n* For information visit https://dt-url.net/functions-help\n*/\nimport { queryExecutionClient } from '@dynatrace-sdk/client-query';\n\nexport default async function () {\n  \n  var query = `fetch bizevents\n  | filter event.type==\"batchprocessing\"\n  | summarize collectDistinct(runId), by:{\\`batchjobs-status\\`,timestamp,\\`job-name\\`}\n  | expand \\`collectDistinct(runId)\\`\n  | fieldsAdd humanreadable=formatTimestamp(timestamp, format:\"hh:mma dd/MM/yyyy\")`;\n\n  const response = await identifyBatch(query);\n  return response;\n}\n\nfunction calculateMedian(numbers) {\n    var sorted = numbers.slice().sort(function(a, b) { return a - b; });\n    var middle = Math.floor(sorted.length / 2);\n\n    if (sorted.length % 2 === 0) {\n        return (sorted[middle - 1] + sorted[middle]) / 2;\n    }\n\n    return sorted[middle];\n}\n\n//Function to fetch jobs during an execution\nasync function fetchJobs(startTime, endTime, jobname) {\n  const query = `fetch logs,scanLimitGBytes: -1, from:\"${startTime}\",to:\"${endTime}\"\n| filter matchesPhrase(content, \"${jobname}\") AND  matchesPhrase(content, \"RunID\")\n| parse content , \"\nLD 'JOBS.' WORD:Job\nLD 'RunID ' STRING:RunId\nLD:status\"\n| fields timestamp, Job, status, content, RunId\n| filterOut status == \".\"\n| fieldsAdd start_time=if(contains(content,\"started.\"),timestamp)\n| fieldsAdd end_time=if(contains(content,\"ended normally.\"),timestamp)\n| fields timestamp, content, Job, status, RunId,start_time,end_time`;\n  \n  const timeout = 60;  \n  try {\n    const response = await queryExecutionClient.queryExecute({ \n      body: { \n        query, \n        requestTimeoutMilliseconds: timeout * 1000, \n        fetchTimeoutSeconds: timeout \n      } \n    });\n    //console.log(response.result.records);\n    return response.result.records;\n  } catch (error) {\n    console.error('Error executing identifyNoofJobs:', error);\n    throw error;\n  }\n}\n\nfunction categorizeJobs(recordSet) {\n  var batch = {};\n  var statusLocked = {}; // Lock the status once we find exit return for a runId\n\n  console.log(\"Total records:\", recordSet.length);\n\n  for (var i = 0; i < recordSet.length; i++) {\n    var record = recordSet[i];\n    var runId = record['RunId'];\n    var status = record[\"status\"] ? record[\"status\"].trim() : \"\";\n\n    if (!batch[runId]) {\n      batch[runId] = {\n        Job: record[\"Job\"],\n        runId: runId,\n        Status: \"\",\n        JobStarted: null,\n        JobEnded: null,\n        Duration: null\n      };\n      statusLocked[runId] = false;\n    }\n\n    if (record[\"start_time\"]) {\n      batch[runId].JobStarted = record[\"start_time\"];\n      batch[runId].BatchStarted = record[\"humanreadable\"];\n    }\n      \n    if (record[\"end_time\"]) {\n      batch[runId].JobEnded = record[\"end_time\"];\n      batch[runId].BatchEnded = record[\"humanreadable\"];\n    }\n    \n    // Update status field for runId only if it's not locked\n    if (!statusLocked[runId]) {\n      if (status.toLowerCase().indexOf(\"exited with error code\") !== -1) {\n        batch[runId].Status = \"Failed\";\n        statusLocked[runId] = true;\n      } else if (status) {\n        if (status == \"started.\") {\n          batch[runId].Status = \"Started\";\n        }\n        else if (status == \"ended normally.\") {\n          batch[runId].Status = \"Completed without errors\";\n          statusLocked[runId] = true;            \n        }\n        else {\n          batch[runId].Status = status;\n        }\n      }\n    }\n\n    //console.log(\"Updated Status for RunId \" + runId + \": \" + batch[runId].Status);\n  }\n\n  var batchList = Object.values(batch);\n  var total_jobs = batchList.length;\n  var jobs_without_errors = 0;\n  var erroneous_jobs = 0;\n  var other_jobs = 0;\n  var durations = [];\n\n  console.log(\"Total unique jobs:\", total_jobs);\n\n  // Count the jobs by status\n  for (var i = 0; i < batchList.length; i++) {\n    var job = batchList[i];\n    console.log(\"Job \" + job.run_id + \" final status: \" + job.Status);\n\n    if (job.JobStarted && job.JobEnded) {\n        var startTime = new Date(job.JobStarted);\n        var endTime = new Date(job.JobEnded);\n        var duration = (endTime - startTime) * 1000; // Duration in seconds\n        job.Duration = duration;\n        durations.push(duration);\n    }\n   \n    if (job.Status === \"Completed without errors\") {\n        jobs_without_errors++;\n      } else if (job.Status === \"Failed\") {\n        erroneous_jobs++;\n      } else {\n        other_jobs++;\n      }\n  }\n  var median_duration = durations.length > 0 ? calculateMedian(durations) : null;\n\n  console.log(\"Jobs without errors:\", jobs_without_errors);\n  console.log(\"Erroneous jobs:\", erroneous_jobs);\n\n  const percentage_jobs_without_errors = (jobs_without_errors/total_jobs) * 100;\n  const percentage_errorneous_jobs = (erroneous_jobs/total_jobs) * 100;\n  const percentage_other_jobs = (other_jobs/total_jobs) * 100;\n  \n  return {\n    total_jobs: total_jobs,\n    jobs_without_errors: percentage_jobs_without_errors,\n    erroneous_jobs: percentage_errorneous_jobs,\n    other_state: percentage_other_jobs,\n    duration: median_duration,\n  };\n}\n\n//Function to identify the completed batch executions timeframe\nasync function identifyBatch(query) {\n  const timeout = 60;\n  try {\n    const response = await queryExecutionClient.queryExecute({ \n      body: { \n        query, \n        requestTimeoutMilliseconds: timeout * 1000, \n        fetchTimeoutSeconds: timeout \n      } \n    });\n    const recordSet = response.result.records;\n    var jobMap = {};\n  \n    for (var i = 0; i < recordSet.length; i++) {\n      var entry = recordSet[i];\n      var key = entry['job-name'] + '_' + entry['collectDistinct(runId)'];\n      \n      if (!jobMap[key]) {\n        jobMap[key] = {\n          parent_jobName: entry['job-name'],\n          parent_runid: entry['collectDistinct(runId)'],\n          parent_batchStartTime: null,\n          parent_batchEndTime:null,\n          parent_startTime: null,\n          endTime: null\n        };\n      }\n  \n      var job = jobMap[key];\n      if (entry['batchjobs-status'] === 'STARTED') {\n        job.startTime = entry.timestamp;\n        job.batchStartTime = entry.humanreadable;\n      } else if (entry['batchjobs-status'] === 'COMPLETED') {\n        job.endTime = entry.timestamp;\n        job.batchEndTime = entry.humanreadable;\n      }\n    }\n  \n    var result = [];\n    for (var key in jobMap) {\n      if (jobMap.hasOwnProperty(key)) {\n        var job = jobMap[key];\n        if (job.startTime && job.endTime) {\n          const jobslist=await fetchJobs(job.startTime,job.endTime,job.jobName);          \n          const total = await categorizeJobs(jobslist);\n          job.totalJobs = total['total_jobs'];\n          job.successfulJobs = total['jobs_without_errors'];\n          job.errorenousJobs = total['erroneous_jobs'];\n          job.unknownStateJobs=total['other_state'],\n          job.duration = total['duration']\n            \n          result.push(job);\n        }\n      }\n    }\n    return result; \n  } catch (error) {\n    console.error('Error executing query:', error);\n    throw error;\n  }\n}","visualization":"table","visualizationSettings":{"thresholds":[{"id":1,"field":"errorenousJobs","title":"","isEnabled":true,"rules":[{"id":0,"color":{"Default":"var(--dt-colors-charts-status-ideal-default, #2f6863)"},"comparator":"≥","label":"","value":0},{"id":1,"color":{"Default":"var(--dt-colors-charts-status-warning-default, #eca440)"},"comparator":"≥","label":"","value":2},{"id":2,"color":{"Default":"var(--dt-colors-charts-status-critical-default, #c4233b)"},"comparator":"≥","label":"","value":15}]},{"id":2,"field":"successfulJobs","title":"","isEnabled":true,"rules":[{"id":0,"color":{"Default":"var(--dt-colors-charts-status-ideal-default, #2f6863)"},"comparator":"≥","label":"","value":85},{"id":1,"color":{"Default":"var(--dt-colors-charts-status-warning-default, #eca440)"},"comparator":"≥","label":"","value":80},{"id":2,"color":{"Default":"var(--dt-colors-charts-status-critical-default, #c4233b)"},"comparator":"≥","label":"","value":0}]},{"id":3,"field":"unknownStateJobs","title":"","isEnabled":true,"rules":[{"id":0,"color":{"Default":"var(--dt-colors-charts-status-ideal-default, #2f6863)"},"comparator":"≥","label":"","value":0},{"id":1,"color":{"Default":"var(--dt-colors-charts-status-warning-default, #eca440)"},"comparator":"≥","label":"","value":5},{"id":2,"color":{"Default":"var(--dt-colors-charts-status-critical-default, #c4233b)"},"comparator":"≥","label":"","value":10}]}],"chartSettings":{"gapPolicy":"connect","circleChartSettings":{"groupingThresholdType":"relative","groupingThresholdValue":0,"valueType":"relative"},"categoryOverrides":{},"curve":"linear","pointsDisplay":"auto","categoricalBarChartSettings":{"categoryAxisLabel":"parent_jobName","valueAxisLabel":"totalJobs","tooltipVariant":"single","categoryAxis":"parent_jobName","valueAxis":"totalJobs"},"truncationMode":"middle"},"singleValue":{"showLabel":true,"label":"","prefixIcon":"","recordField":"element","autoscale":true,"alignment":"center","colorThresholdTarget":"value"},"table":{"rowDensity":"condensed","enableSparklines":false,"hiddenColumns":[["startTime"],["endTime"]],"lineWrapIds":[],"columnWidths":{"[\"cpu\"]":205.796875,"[\"Service\"]":127.71875,"[\"totalJobs\"]":155.0859375},"enableThresholdInRow":false,"colorThresholdTarget":"value"},"honeycomb":{"shape":"hexagon","legend":{"hidden":false,"position":"auto"},"colorMode":"color-palette","colorPalette":"blue","dataMappings":{"value":"totalJobs"},"displayedFields":["parent_jobName"]},"histogram":{"dataMappings":[]},"unitsOverrides":[{"identifier":"totalJobs","unitCategory":"unspecified","baseUnit":"count","displayUnit":null,"decimals":0,"suffix":"","delimiter":false,"added":1726493334206},{"identifier":"successfulJobs","unitCategory":"percentage","baseUnit":"percent","displayUnit":null,"decimals":1,"suffix":"","delimiter":false,"added":1726493399642},{"identifier":"errorenousJobs","unitCategory":"percentage","baseUnit":"percent","displayUnit":null,"decimals":1,"suffix":"","delimiter":false,"added":1726494918710},{"identifier":"unknownStateJobs","unitCategory":"percentage","baseUnit":"percent","displayUnit":null,"decimals":1,"suffix":"","delimiter":false,"added":1726498980559},{"identifier":"duration","unitCategory":"time","baseUnit":"microsecond","displayUnit":null,"decimals":1,"suffix":"","delimiter":false,"added":1726499008645}]},"querySettings":{"maxResultRecords":1000,"defaultScanLimitGbytes":500,"maxResultMegaBytes":1,"defaultSamplingRatio":10,"enableSampling":false}},"2":{"type":"markdown","title":"","content":"----\nBatch Execution Details\n----\n-----\n"},"3":{"type":"markdown","title":"","content":"----\nBatch Job Impact: Correlated metrics for Application, DB, Messaging Queues during Batch Execution\n----\n-----\n"}},"layouts":{"0":{"x":0,"y":2,"w":24,"h":7},"1":{"x":0,"y":11,"w":24,"h":7},"2":{"x":0,"y":9,"w":24,"h":2},"3":{"x":0,"y":0,"w":24,"h":2}},"importedWithCode":false}